version: "3"
services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: backend
    volumes:
      - .:/open-llms-next-web
    networks:
      - llm
    ports:
      - "5000:5000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: "nvidia"
              count: "all"
              capabilities: ["gpu"]
    command:
      - /bin/sh
      - -c
      - |
        uvicorn main:app --host 0.0.0.0 --port 5000  --reload

networks:
  llm:
    external: true